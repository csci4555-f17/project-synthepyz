\documentclass{article}
\usepackage{todonotes}
\usepackage{tikz}
\usepackage{listings}

% Insert liner notes using these commands
\newcommand{\nlsays}[1]{\todo[color=orange!40]{NL: #1}}
\newcommand{\sdsays}[1]{\todo[color=blue!40]{SD: #1}}
\newcommand{\wtsays}[1]{\todo[color=green!40]{WT: #1}}

\title{Matching Reference Behavior \\ by Simple Enumerative Synthesis}

\author{
  Souradeep Dutta \and
  Nicholas V. Lewchenko \and
  William Temple
}

\begin{document}

\maketitle

\nlsays{Just my first idea for the title; suggest your own}

\nlsays{Authors are alphabetical; we can rearrange by significance or
  whatever if desired}

\section{Introduction}
\label{sec:introduction}

\begin{figure}
  \centering
  \input{fig-exp}
  \caption{An exponentiation node in Python (a) translated into the
    arithmetic theory definition (b) and then x86 assembly
    implementation (c).}
  \label{fig:exp}
\end{figure}

Writing a compiler is difficult, in part because it requires a
programmer to implement the core functionality of their source
language in one or more assembly languages.
%
An assembly language is optimized for simple evaluation by a computer
(simple enough that \emph{hardware} can do it).
%
The consequence of this design requirement, illustrated in
Figure~\ref{fig:exp}, is that non-trivial assembly programs grow
large, and writing or reasoning about them is tedious and error-prone
for a human.
%
The difference in complexity between the fully-specifying formal
definition of an operation and its assembly implementation is
dramatic, suggesting that computer assistance in this implementation
process would significantly reduce the necessary programming effort of
a compiler programmer.

\section{Background}
\label{sec:background}

One of the promising ideas in Program synthesis is that of Sketching, explained
in \cite{phdthesis}. The idea in the Sketching program model is to allow the
programmer a robust scheme to tailor in the basic implementation outline while
leaving some of the details to the synthesizer. The programmer is expected to
come with the assertions in order to specify the correct behavior of the
program while giving the outline. The SKETCH Language is basically a layer on
top of a simple procedural language, with the only difference being the
introduction of the integer hole \textbf{??}.  Where the programmer expects the
integer hole to be replaced with a suitable integer.  \\ The "Hello World" in a
SKETCH programming model can be the following program, \\ \\ \textbf{void} main
(int x) \{ \\ int y = x * ?? ; \\ assert y == x + x; \\ \}

The three basic components of a SKETCH model are the following: i) the main
procedure , ii) holes, and iii) assertions.  The synthesizer is only allowed to
the fill up the holes with appropriate integer and not introduce any new lines. 

Another interesting idea in program synthesis is that of using enumerative
learning to come up with the expression. This idea is known by the name of
Syntax Guided Synthesis also known as \textbf{SyGuS} \cite{sygus}. Now, from a
top level the function synthesis problem is basically trying to find a function
$F$ such that some specification $\Phi$ is valid. The specification is expected
to capture the correctness of the desired program. For the syntax guided
synthesis problem it is constrained in the following ways:

\begin{itemize}
    \item The interpretation of the logical symbols and connectives
	are restricted to the background theory only.
    \item The logical formula $\Phi$ is only limited to be first order formulae in
	the back ground theoy.
    \item The possible functions are only restricted to be syntactic expressions
	generated by the grammar.
\end{itemize}

The main procedure in syntax guided synthesis is shown in Fig \ref{sygus_fig}.  
\begin{figure}
\label{sygus_fig}
\includegraphics[scale = 0.8]{workflow.png}
\caption{SyGuS procedure \cite{sygus}}
\end{figure}

It essentially involves generating expressions and asking a verification oracle
to check the correctness of the generated expressions. If correct then , we
have the right function. Else, the oracle comes up with a counter example, and
the learning uses the Counter Example to refine it's search procedure. This
process is typically known in literature as a Counter Example Guided Inductive
Synthesis procedure or $CEGIS$.

This sort of enumerative synthesis algorithm though very simple to understand
and implement, can quickly become quite computationally expensive and
infeasible in practice when we try to generate even decent sized programs.

\section{Our Approach}
\label{sec:approach}

We have defined and implemented an enumerative synthesis procedure called
\textsc{SomeName} \nlsays{Will should give the tool a name.} for operation
implementations in a compiler for which a reference interpreter is available.
Our technique is source-language agnostic, using the preexisting reference
interpreter to produce a fixed set of test cases against which x86 programs
are sought.  This reference-guided partial verification reduces the complexity
of the technique.

\subsection{Virtual x86}

We define \textit{Virtual x86} (or vx86) to be a subset of the x86 language
where hardware registers have been replaced with infinitely many virtual,
indexed storage locations that behave exactly like hardware registers.  The
vx86 machine has the following properties:

\begin{itemize}
    \item Any instruction in vx86 has the same operating semantics as in
	regular x86.
    \item Only virtual registers are valid locations (there is no address
	space, nor any alternative addressing modes)
    \item No instructions which may alter the behavior of a future instruction
	are permitted
\end{itemize}

By limiting x86 in this way, we define a language which allows us to
recursively enumerate all possible programs and consider their behaviors
incrementally.

\subsection{Synthesis}

\wtsays{This is where I've gotten to so far, wanted to post this before
continuing to work.}

\subsubsection{Generation}

\subsubsection{Validation}

\subsubsection{Pruning}

\subsection{Generating Tests}

As our synthesis algorithm describes a general method for discovering programs
that satisfy a set of constraints, it is therefore also desirable to automate
test generation.  In our example scenario, we do this by interrogating a
reference interpreter using a random distribution of input values to produce
a suite of tests which are \textit{probably} comprehensive.

Given a $k$-ary operator, we will choose tests based on
\begin{itemize}
    \item all combinations of the numbers one and zero (based the fact that
	these are the multiplicative and additive identities, respectively),
	and
    \item a sample of values chosen by the result $f(x)=x^{9}$ for random
	values of $x$, up to a certain threshold
\end{itemize}

Because the synthesis engine is slow, it is desirable to generate a suite of
test cases that covers both the boundary cases around zero and one as well as
a probabilistic subset of the larger space of integers in as few tests as
possible.

\subsection{Implementation}
\label{sec:implementation}

We implemented a proof-of-concept of \textsc{SomeName} in Rust \ref{appendix-a}
\wtsays{what's the best way to inline this, or reference it}.  The
implementation follows the algorithm given above, but contains some
optimizations.  Most notably (from a performance standpoint), we compute the
results of each program incrementally (each Program contains a reference to its
parent program, its set of registers, and the instruction that makes it unique
from its parent), where each program is simulated only as an incremental change
from the results of the program that generated it.

\section{Evaluation}
\label{sec:evaluation}

\ldots \wtsays{Still working on this section, more to come.}

\section{Conclusion}
\label{sec:conclusion}

We believe that this technique presents a novel method for synthesizing
transformations from a high-level language to a machine language by leveraging
an existing interpreter (or any model by which expressions in the high-level
language may be automatically evaluated).  Our goal is not to eliminate the
work of writing a compiler, only to show that the most mundane aspects of
compiler design may be automated in some cases.  We are interested in how this
approach may be integrated with more conventional synthesis/verification
approaches involving, for example, SMT or SAT solvers, as our method is fast
for small operations though large programs remain intractable.  We believe that
this method may be useful for constructing the basic building blocks of a
compiled language, from which more advanced synthesis techniques may build more
comprehensive programs, utilizing the artifacts of our synthesis engine as
basic components.

\section*{Acknowledgements}

We thank Steven Malis (Software Engineer, Microsoft, Inc.) for his inspiration
and assistance with the incremental simulation optimization in our
proof-of-concept code, and for his permission to use this idea in our
implementation.

\bibliographystyle{plain}
\bibliography{references}	

\end{document}

